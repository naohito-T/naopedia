# DB
[学習効率を上げるためのバックエンドのデータベース基礎知識](https://devsakaso.com/about-database-basics/)  
[瞬殺でDBを使って何かしたいとき](https://zenn.dev/takuho/articles/efc40344f3122e)  
[DockerでサクッとDBからER図を作成する](https://qiita.com/kamukiriri/items/ab1669c19831c18db9ee)  
[データベース設計の際に気をつけていること](https://tech.tabechoku.com/entry/2020/06/15/132518)
[SQLスキーマを改善する](https://sisense.gaprise.jp/blog/0032)

RDB & NoSQLなどDB関連のページ

## DBに求める機能と要件

データベースを選択するときに検討するべき要件を整理

### データ量を考慮する

データベースに保存するデータ量がどれぐらいの規模なのかを検討する必要があります。  
データ量の単位はデータサイズでも表現できますし、データ件数でも表現できます。たとえば、数万件規模のデータ量なのか、数百万件規模のデータ量なのか、数億件規模のデータ量なのかによっても変わるため、データ量を整理しておくことは重要。

### データ増減パターンを考慮する

データ量がある程度一定に保たれるのか、大きく増減するのかという観点での検討も重要  
たとえば、何かしらのマスタデータであればデータ量が大きく変化することはありません。  
また週次でデータが1件ずつ増える場合も一年間で52件しか増えませんので、大きく変化することはありません。  
しかし、購入履歴データであれば、ユーザー数と購入件数によって大きく増えていく可能性があります。このように、データ増減パターン（とくに増える場合）という観点で整理することは重要です。

## 保持期間を考慮する

保持しているデータをいつまで保持するのかを整理する必要がある。  
たとえば、直近1年のデータのみ必要で、それ以降は削除できるケースであれば、1年間の最大のデータ量を前提に設計できます。  
この場合、データに対してTTL（TimeToLive：有効期限）を設定できるツールやサービスを利用することで、不要となったデータを効率的に削除できます。

ほかには、アプリケーションとしては必要がなくても、第三者機関の監査ポリシーなどにより、数年間残しておく必要があるケースもあります。

## アクセスパターンを考慮するc

アクセスパターンとは具体的には**参照（検索も含む）・追加・更新・削除**などがある。  
データベースはアプリケーションからどのアクセスパターンを受け入れるのか、そしてそれぞれの利用回数に傾向はあるのかも検討する必要があります。  
具体的に例を挙げると、一度追加されたらその後は参照が多くなるパターン（ReadHeavyと言います）もあれば、追加されたデータの参照は比較的少なく新規の追加が多くなるパターン（WriteHeavyとも言う）もあります。


書籍サービスなどではアクセスパターンとして参照パターンが多い。

## 形式を考慮する

保存するデータの種類や形式を整理することも重要。  

AWSでは以下の形式で整理している。  
- リレーション
- キーバリュー
- インメモリ
- ドキュメント
- ワイドカラム
- グラフ
- 時系列
- 台帳

## DBの要件を整理後

**データベースはアプリケーションで実現したい要件に最適**だからという理由で選択するべき。  
こういった考え方をPurpose built databaseと言います。  
そして、AWSにはPurpose built databaseを実現するために、多くのデータベースサービスがあります。  
[![Image from Gyazo](https://i.gyazo.com/c014051e2ab0992b9412a5f01e1890cc.png)](https://gyazo.com/c014051e2ab0992b9412a5f01e1890cc)

## 触る時に考えること

- 本番を触る時はすべてエビデンスをとれ（スクショなど）
- 何をしたのかしっかりと伝えられること。そのためのエビデンス
- CRUDの内のC(create)U(update)D(delete)をする前には必ずselectをしろ
- indexは大体どこのSQLでも単一の値にはインデックスが貼られている。
→ しかし複数の値での検索時はインデックスが貼られていないため検索回数が多いのは検討をしインデックスを貼る。

## DB設計の時の考え方

どうせ最初からパーフェクトなテーブル設計はできない。  
最初は完璧になんて不可能なので、ある程度考え、実装し、間違っていればまたやり直す。を繰り返すことが一番の近道。  
あ、どうせ変化していくものなので完璧を求めすぎないこともポイント。

## DB 検索は 1 回で終わらせる。

DBにアクセスする部分は**一度の検索で終わらせるべき。**（処理が重いため）  
ただ副問い合わせなどをするとパフォーマンスはどちらが上なのかは知りたい

## データベース設計の際に気を付けること
[参考URL](https://tech.tabechoku.com/entry/2020/06/15/132518)

1. 制約をつける
データベース設計において重要なのは**いかにして不整合を起こさないようにするか。**  
「データを引いてみたら関連先のレコードが無くなっている」、「このレコードはユーザーごとに1つだけ持つはずだけど、2レコードある」など。 不整合は往々にして発生する。  
データを挿入・更新・削除してもよいかの**チェックはアプリケーションレベルで防ぐだけではなく、可能ならばデータベースレベルでも行う。**

そのために、以下制約をつける努力をする。
  1. 外部キー制約をつける
  2. ユニークキー制約をつける

## Table Entity関係を書く

ER図を書いていくことになる（デファクトスタンダード）

## table 命名規則
[参考URL](https://qiita.com/tatsuya_1995/items/4b706fc40fe2f300bbc0)

## 一時的なレコードと永続化が必要なレコードを同じテーブルには入れない
[設計参考](https://tech.tabechoku.com/entry/2020/06/15/132518)  
>構造が同じでも意味が違うデータは分けて管理すべきだと、私は思います。 その方がレコードの行数も少なく抑えられて、注文テーブルを引くコストが下がります。

## SQL設計
[DB・テーブル設計のプラクティス](https://neos21.net/tech/design/db-table-practices.html#%E3%83%80%E3%83%9F%E3%83%BC%E3%83%87%E3%83%BC%E3%82%BF)  
[SQLアンチパターンを避けるためのチェックリスト①（DB論理設計編）](https://www.ketancho.net/entry/2018/03/07/080000)

## DBマイグレーション

データベースを削除し手から作り直すと、DBに保存されている情報がすべて削除される。  
こういった事態を回避する方法としてデータベースマイグレーションを行う方法がある。  
マイグレーションとは、**DBに保存されているデータを保持したままテーブルの作成やカラムの変更などを行うための機能。**  
運用中のデータベースにデータを入れたまま、テーブルを追加したりカラムを変更するなどして、スキーマを管理する機能   
※対象の言語ORMに対して、マイグレーションがない場合は汎用なマイグレーションツールを使うなど対策が必要

## パスワード保存について

データベースに生の（平文の）パスワードを保存するのは情報セキュリティの観点から望ましくない。  
**その代わりにパスワードのハッシュ値を(あるいはダイジェスト)と呼ばれる値をデータベースに保存するのが定石**

## アプリケーションからのDB基本利用法

アプリケーションからDBにアクセスするためにはデータベース固有のプロトコルを用いてアクセスする必要があり、各DB向けに実装されているドライバーを使う。
一方アプリケーション側から呼び出す接続コードは、データベースドライバーの実装に依存しない汎用的なAPI

## DBバックアップについて

ダンプのファイル量が多いと時間がかかる。  
そのため、その際にデータの書き換えがあるとデータの相互性が失われる。  
そのためデータのバックアップを取得するときは**DBを停止して行うべき**

## DB種類

- キーバリューストア
memcachedやRedis

## DB分割構成

Webアプリケーションの規模が大きくなると応答速度の低下が問題になることがあり、ボトルネックとなるのはDBアクセスに関する部分。  
そういった問題を解決し、複数のDBを利用するgemパッケージとしてOctopusなどがあったがRails6.0からはRails標準機能として複数DBへ対応した。  

しかし、実際に複数DBとして望まれるケースで多いのは**書き込みと読み込みの負荷を軽減させるために書き込む用のデータベースと、そのデータを同期した読み取り用データベースに分割する構成。**

書き込み用データベースを**プライマリーDB**
レプリケートした読み取り専用データベースを**レプリカDB**


上記の構成の場合、レプリカDBへ直接マイグレーションの適用やデータの書き込みは行わない（RailsではレプリカDBであると明示するため`database.yml`にreplicaを指定する）
実運用ではレプリカDBへの接続は参照権限のみのユーザで接続するのが望ましい。

## リードレプリカ(read replica)

リーどレプリカとは、DBの負荷分散のために作成される**参照専用の複製。**
データの更新＆追加は行わず検索や読みこみのみを行う。

## データベースのスキーマ
[参考URL](https://www.miracleave.co.jp/contents/217/db-table-schema/)

1. MySQLではDBとスキーマは同じと思って良い
2. PostgreSQLではデータベースがあってその下にスキーマが存在する（デフォルトでpublicスキーマが作成される）

## リレーションの読み込み方
[わかりやすい](https://cloudsmith.co.jp/blog/backend/laravel/2020/07/1506704.html)

### Eager Loading 訳：熱望的なローディング or 積極的なリレーションシップ

Eager Loadingでは、2つのテーブルのデータを1度に取得する（関連のも）  
Eager Loadingを使うと、クエリの発行回数を減らすことができるので、いわゆる「N＋1問題」の回避策として用いられる。

### Lazy Loading 訳：怠惰なローディング

リレーションの際、親テーブルからデータA取得する。次に子テーブルから（便宜上、親テーブルのidを持っているもの）データAのidに関連するデータを取得する。  
というように2回に分けてデータを取得すること。

## N＋１問題とは？

クエリの発行回数が過剰に増えて、サーバーサイドでタイムアウトエラーなどの不具合を起こしてしまう現象のこと

## データベーススキーマ設計の完全ガイド
[参考URL](https://www.integrate.io/jp/blog/complete-guide-to-database-schema-design-guide-ja/)


ーブルのROW_FORMATがDynamic(Barracuda)であることを確認する
- MySQL5.6まではデフォルトのフォーマットはCompact(Antelope)でしたが、これは1レコードあたり8KBまでしかデータを入れることができません。
テキスト型を使うと8KB制限を突破してしまうこともあるため、テーブルのフォーマットがDynamic(Barracuda)であることを確認します。
- 整数値を入れる場合はint型かbigint型を使う
- float型は使わない
- 精度のトラブルに巻き込まれたくないためfloatは使いません。多くの場合、doubleかdecimalで問題ありません。
金額情報など、精度を求められる小数値にはdecimalを使う
doubleも小数点以下の精度に悩まされることがあります。金額を扱う、精度が必要な計算は必ずDecimalを利用します。
- 日付を入れる場合はDATE型を使う
- 商品のお届け日など、日付を入れる場合はDatetimeやTimestamp型ではなくDATE型を使うようにします。DatetimeやTimestampはタイムゾーンの影響を受けるためです。
- JSON型を使ったら負け


郵便番号や電話番号のnumberかstringかの悩み
- 算術計算の対象ではないのでstringにする。

## 命名規則
[参考URL](https://qiita.com/genzouw/items/35022fa96c120e67c637)

1. 大文字を利用しない。
テーブル名、カラム名ともに大文字を利用しない。
（DBにより大文字小文字を区別するもの、しないものなどがあるため小文字で統一を図る）

2. 複数単語の連携はスネークケース
テーブル名、カラム名ともにスネークケースを利用する。
キャメルケース、キャメルバックはNG。

## DB・テーブル設計のベストプラクティス
[参考URL](https://neos21.net/tech/design/db-table-practices.html)

## テーブル 複数形 vs 単数形
[参考URL](https://medium.com/@fbnlsr/the-table-naming-dilemma-singular-vs-plural-dc260d90aaff)
[参考URL](https://qiita.com/siinai/items/d4274c95fcdde3fd7295)

実際のところWEB系のフレームワークなどは複数形を好むため、複数形のテーブル名に慣れ親しんでいる人は多い。

## 空文字 or NULL
[参考URL](https://ja.stackoverflow.com/questions/66361/mysql%e3%81%aevarchar-%e3%83%87%e3%83%bc%e3%82%bf%e5%9e%8b%e3%81%ae%e5%88%9d%e6%9c%9f%e5%80%a4%e3%81%a7-null-%e3%81%a8%e7%a9%ba%e6%96%87%e5%ad%97%e3%82%92%e3%81%a9%e3%81%ae%e3%82%88%e3%81%86%e3%81%ab%e4%bd%bf%e3%81%84%e5%88%86%e3%81%91%e3%82%8b%e3%81%b9%e3%81%8d%e3%81%8b)

空文字だと、電話番号を持っているが電話番号がない。というようなよくわからない事情がでる。
そのため持っていないのであれば`NULL`にした方がいいかも。
> データが存在しないのならば、素直にNULLを入れるべきです。



## OAuth2.0のユーザーテーブル設計
[これが分かりやすい](https://zenn.dev/pyhrinezumi/articles/8455f0d61e856f)

## エンティティ保存方法を考える

>このエンティティの識別子の生成方法には様々な種類がありますが，大きく分けて永続化前に生成する早期生成と永続化後に生成する遅延生成の2種類に分けられます

---

## id 設計

主キーは**検索のキー**として利用されたり、他の関係に参照のために格納されたりする確率が高いため、できる限り**データ量の小さい方がよい。**
よって複合キーはあまり適さない。

## ナチュラルキーとサロゲートキーはどちらがいいのか
[参考URL](https://amg-solution.jp/blog/8980)

### ナチュラルキー（自然キー）

キーそのものに意味が含まれているキーで、業務的にそのテーブルをユニークにするキーをナチュラルキーという。
要は入力データ自体をPKとして場合、PKはナチュラルキーとなる。
たとえば、以下のようなテーブル構成の場合のユーザーテーブルのユーザーコードのように、それだけで意味のわかるキーがPKとなっている場合、ナチュラルキーと言います。

### サロゲートキー(代理キー)

ナチュラルキーに対して、業務上は意味を持つ値ではないが、システム的に一意な値をとるようオートインクリメントなどで連番を振り、PKとしているテーブルのPKのことをサロゲートキー（代理キー）と呼びます。

>サロゲートキーの特徴
- テーブル間の依存関係が薄くなる
- アプリケーションの画面間引き継ぎ情報や実装などを統一できる
- 複合主キーのテーブルに比べSQLが簡潔になる
- 業務上は意味のないキーを持つので、容量を余分に使う

## サロゲートキーはアンチパターンとも言われている

（アンチパターンとも言われますが）サロゲートキーとしてidなどの自動採番の数値を主キーとする設計も現場では多く(ORMを使っているケースだったり、セカンダリインデックスにプライマリーキーが含まれることによるインデックスサイズの増加を懸念したり)、その様な場合に主キーの値の変更はそこまであるケースではないため、カスケード更新自体が登場する機会は少ないかもしれません。


### uuidで使う
[参考URL](https://zenn.dev/dowanna6/articles/3c84e3818891c3)

メリット
- users/1とかでプライマリキーを連番にすると推測されやすい。スクレイピングされやすいのを回避できる（書いてて思ったけど、idをencryptすればいいじゃね？CFCみたいな）


デメリット
- insertが完了するまでidがわからない。
- DBクライアントによっては処理が落ちる（MySQL (InnoDB) ではプライマリキーにランダムな値を用いるとINSERTの効率が落ちてしまいます）

処理に時間がかかる場合、先にidだけ返して永続化処理は非同期に実施することがときどきありますよね（画像アップロードとか）
こういう時もDB側での採番だと実際DBにinsertするまではidが確定しないので、本当は今この瞬間にinsertする必要がなくても採番するためだけにDBとのI/Oが発生することになります。同時にたくさんのファイルをたくさんのユーザーがアップロードするよ！みたいな機能を作りたい時にちょっとパフォーマンスが心配ですよね

### プライマリキーにULIDを使う
[参考URL](https://zenn.dev/emiksk/articles/e2716c0af75eea)

---

## 外部キー制約

参照されるのが
親テーブル

参照するのが
子テーブル

## リレーションシップの種類

- 依存リレーションシップ
子テーブルの存在が親に依存している場合

- 非依存リレーションシップ
子テーブルの存在が親に依存していない場合


## 多対多

多対多の関係の場合にどうテーブル設計をすれば良いかわからなくなってしまいがち。
>そうなんです。多対多の関係の場合、どう頑張っても良い設計にならないのです。
ですのでそもそも**多対多の関係にならないような設計が必要**で、その解消方法は**中間テーブルを用意し1対多の関係になるように設計することが必要**

## 論理削除の可否
[twadaさんに語ってもらった](https://fukabori.fm/episode/27)
論理削除はアンチパターンのひとつだが割とよくある設計。

>レコードを消したい。でも消したくないみたいな時に削除フラグ項目を設け、レコードをDELETEするのではなく削除フラグをUPDATEして、SELECTの条件で削除フラグがTRUEなら取得しないようにするやつです。

頻繁に復活させたり、レコード数が少ないテーブルに設けるのであれば検討の余地はありますが、基本的には論理削除を用いないほうが良いでしょう。

## 内部結合と外部結合の違い
[参考URL](https://style.potepan.com/articles/14926.html#SQL)


## DBパフォーマンス関連

## チューニング
[LEFT JOINとORDER BY](https://gist.github.com/kano-e/8d75be08037809fd280d/4d9800a5237e17df49027f9a96f092d2e45a7635)

速度低下の原因はSQLが内部的にどのような処理を行っているかを表示させるexplainで見ることができる。

- SQLが遅い場合は、explainである程度遅い原因を確認できる
- 件数が多いテーブルで重い処理が実行されているときは要注意
- なるべくインデックスを使って処理されるよう、order byなどの指定を変えてみる

## ORDER BYで起こること

`ORDER BY`使うと全部並べ替えようとする。  
ORDER BY使わずにSELECTするのは速いけど、実際の業務では現実的ではないため使用しない。
インデックス使うのが一般的  
インデックスはソートされているようなものなので、インデックスがあればORDER BYはインデックスを元に行われる

## LEFT JOIN で起こること

LEFT JOINする時、大抵はONでJOINの結合条件を設定する。
FROMに指定した`テーブルA`のレコードが10_000件、JOINに指定したテーブルBのレコードが1_000件あった場合
`テーブルA`のレコードの件数分、`テーブルB`の対象レコードを探す処理が必要になる

これは、最悪の場合10_000_000レコード分の処理になる (10_000 * 1_000)
JOINは掛け合わせなので**元になる情報が大きければ大きいほど、その結果が膨れ上がることになる**
一般的にJOIN遅いって言われているのは、これのせい

## DBに値を入れる基準

データベースに値を入れておくと**外部キーを貼れる**というメリットがある。
システムでの重要ポイントになるような「状態を表す値」を定義する場合に、リストにない値が入ってしまえば混乱しか産まないので、たとえ数個しかなくても外部キー制約のためにテーブルを立てることは、よく行います。

都道府県の場合も、内部的に「都道府県ID」で管理するなら、データベースへの投入はほぼ必須となります。単にリストとして使う場合は、どちらでも構いません（DBのないところで運用できる、というのがDB外で管理するメリットとはなります）


## DBを作るときのTips
[データベースに都道府県データを持たせるべきかどうか](https://teratail.com/questions/99245)


