# インフラ

インフラの設計思想を記述する。
2重起動はしないようにする
自動復旧する

---
## インフラサーバの潮流

### 物理サーバーの時代

インフラといえば、アプリケーションがどれくらい利用されるか予測し**物理サーバを業者に発注**していた。（サーバー調達と言います）
メーカーの都合でハードウェアや仕様が変わったり、求めるサーバーが手に入らないことがあることある。
負荷対策では強いマシンを用意したり、ロードバランサーと複数台のマシンで分散処理します。

**複数サーバーへのデプロイは？**
サーバーが少数台であれば、1台1台にアプリケーションコードを配置（デプロイメント）するのは難しくありません。

rsyncなどのツールを使って効率的にコードを配置していた（昔やっていた）

しかし、サーバー台数が多くなってきたり、さまざまなサーバー(仕様やOS)が混在するようになると難度は上がっていきます。セットアップにミスがあると、サーバーによっては Python が入っていないだとか、バージョンが古いだとか、トラブルを引き起こします。
**こうしたサーバ環境を管理することをプロビジョニング**と言う。
プロビジョニングを行うためPuppet、Ansible、Chefがそれらツールの代表。
サーバーに一括で同じスクリプトを実行することが簡単になった。

### 仮想化技術時代

データセンターでは、サーバー仮想化が普及することになります。 1 台のハイスペックなマシンを、複数台の仮想サーバとして分割するための技術です。

ホストマシンの中で OS とカーネルを仮想化し、ユーザにアプリケーション実行環境を公開します。レンタルサーバの裏側で使われている技術です。

この仮想化技術を使って大量のサーバを保持する会社が、指定したサーバスペックを短時間で調達する IaaS が生まれました。仮想化によってサーバ環境の統一やプロビジョニングが容易になりました。

## Docker の誕生

先程述べた仮想化技術はスーパーバイザ型、ホスト型などと呼ばれ、ホストマシン上でゲストマシンを立ち上げ、 OS やカーネル、アプリケーションを動かします。

これらの技術を使うと、サーバ調達は短時間で簡単に済みます。とはいえ、もっと素早いリソースの調整が求められていました。アプリケーションが主体になっていく流れの中で OS やカーネルまで仮想化が必要なのかという疑問が生まれました。

アプリケーション動作環境をうまく仮想化するだけの技術として Docker が生まれました。 Docker はホストマシンの OS とカーネルを共有し、アプリケーションだけを動作させます。

OS やカーネルを仮想化しない分、短時間で起動が可能です。いまでは Linux ディストリビューションに限らず Window や macOS などで使えるような仕組みに変わっています。

コンテナオーケストレーション
Docker はコンテナと呼ばれる隔離環境でアプリケーションを実行します。 1 台のサーバ上でお互いのプロセスに影響を与えることなく、複数のコンテナを動かすことが可能になります。

となると、どのサーバーにどのコンテナを動かすのかという問題が生じます。これを解決するのが、コンテナオーケストレーションツールです。 Kubernetes や Apache Mesos がそれらにあたります。Apache Mesos は Docker 以前から存在していました。

このようにして簡単に生成・破棄できるコンテナ型仮想化技術が重宝され、新しくオーケストレーションの問題が生まれ、また新しく Kubernetes のようなツールで解決が図られているという流れです。