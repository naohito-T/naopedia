# Docker

## Docker コマンド

近年Dockerコマンドはできるだけ次の書式に統一しようとしている

`$docker コマンド 操作 オプション`

## Docker 参考文献

[Docker での Node 環境構築](https://www.creationline.com/lab/29422)
[Docker 環境構築best practice](https://www.forcia.com/blog/002273.html)

## docker word

デタッチモード: コンテナ内に入らずバックグラウンドで動作する状態のこと。

## こうしたいんだぜという時の逆引きdocker

[参考URL](https://beyondjapan.com/blog/2016/08/docker-command-reverse-resolutions/)

## 開発におけるdocker導入のメリット

[参考URL](https://qiita.com/minodisk/items/5ffd20588b995523756f)

---
**メリット**

- 同一性
複数人で開発する際に、環境の差が生まれない。

- カプセル化
**アプリケーション込みの環境をコンテナというカプセルに隠蔽することができる。**
コンテナという単位に対するテストが可能に。
コンテナを捨てる・再生成するのが容易。

- ポータビリティ（一貫性とも）
開発に使ったコンテナをCIでテストできる。
**CIでテストしたコンテナをサーバーにデプロイできる。**
デプロイしたコンテナをスケールできる。

- 一つのサーバにwebサーバを同居できる(apache)
1台のDockerホストに2台のWebサーバを同居させることができるなど。
>ここまでの操作では、「http://Dockerホスト:8080/」「http://Dockerホスト:8081/」･･･のように、明示的なポート番号の指定での切り替えが必要です。実運用では、きっと、それぞれ、「http://www.example.co.jp/」「http://www.example.com/」など、アクセスするドメイン名で切り替えたいことでしょう。それは可能ですが、少し工夫が必要で、Dockerの力だけではできず、リバースプロキシとして構成します。

**メリットで防げる消耗**

1. おれの環境では動いた。
はい。
複数の開発者で同一の環境で開発できるので防げる。

2. ローカルで通ったテストがCIでコケる。
開発と同一の環境でテストできるので防げる。
bundle install, npm install に失敗してテストがコケる。

3. 依存ライブラリのフェッチに成功したイメージでテストすることで防げる。
コードを変更していないのにアプリケーションの挙動が変わった。go getしてるライブラリの挙動がいつの間にか変わってたぽい。

4. 依存ライブラリをフェッチしたイメージを共有することで、バージョンを固定できる。
nginxの設定を変更したい。サーバにログインするためのSSHキーどれだっけ。
手元で設定して動作を確認しDockerイメージをデプロイすることができるので、設定変更のためにサーバーにログインする必要がなくなる。
さらに、正しく設定できているかブラックボックステストすることも可能に。

**デメリット**

- 学習コスト
コンテナを立ち上げるあたりまではコスト低めだが、実際に開発環境としてDockerを使うあたりから「これどうやってやるんだろう」「どちらの方法で設定するのが良いのだろう」のノウハウが出てくる感じになる。
開発者全員に深い知識が必要かというとそうではないが、問題解決できる知識を持った人間が開発陣に最低一人は必要。

- ローカルでの開発とほぼ遜色ない環境でコードを書くことができるということを周知するためのコスト

---
## DockerFile とは

docker build で image を作成するファイル
**公開されている Docker イメージをそのまま使う場合は必要なく、カスタマイズしたい場合に作成する。**

## Docker build

Dokerfile から docker image を作成するコマンド

`$docker build`

## docker-compose.yml 覚書

コンテナの定義やマッピングするポートなどコンテナに関する設定を記述するファイル

```yml
version: "3"
services:
  app:
    # 起動イメージ
    image: node:16
    # 環境変数
    environment:
      - DEBUG=app:*
    tty: true
    # ホスト側のポート：コンテナのポート
    ports:
      - "3000:3000"
    # ホスト側のsrcをコンテナのappにマウント
    volumes:
      - ./src:/app
    # 起動時のカレントフォルダ
    working_dir: /app
    # 起動後に実行するコマンド
    command: npm start
```

> 重要な箇所は # ホスト側の src をコンテナの app にマウントの部分で、通常 Docker コンテナを停止するとコンテナ上で作成した各種ファイルは削除されますが、上記の記述を行うことでコンテナ起動時に再度ファイルがマウント（反映）されます。
> また Docker コンテナ上で作成・変更したファイルもこちらに記述した場所に反映される。
> 基本ホスト上とコンテナ上でファイルの同期をとるための記述と考えれば OK

## Docker compose 起動 (docker-compose コマンドについて)

`$ docker-compose run --rm app /bin/bash`

※rm オプションは Docker コンテナ停止時にコンテナを削除する機能で、停止したコンテナが残り続ける問題を解決するためのオプション

## Docker コンテナの軽量化

[軽量化参考 URL](https://qiita.com/Canon11/items/da3a7795d894030865f7)

- コンテナイメージサイズが大きいことによる弊害
  イメージのビルド時間が長い
  イメージを Docker Registory にプッシュする時間が長い
  イメージを Pull する時間が長い

それらが起因して下記の弊害が起こる

トライアンドエラーに時間がかかり、生産性が低下
ビルド時間,CI 時間の増大
オートスケールでコンテナがサービスインされるまでの時間が長くなる。
Kubernetes クラスタを構成する Node ディスクの消費

- 軽量化のアプローチ

1. RUN 命令をまとめる
   基本中の基本

※RUN 命令が走る度にイメージレイヤーが生成されてしまうため、ちょっと重くなる。

```dockerfile
# npm installの後のパッケージを羅列
RUN npm install -g gulp@3.9.1 \
    && npm install gulp-load-plugins \
    gulp-plumber \
    gulp-sass \
    gulp-pleeease \
    gulp-uglify \
    gulp-rename \
    && npm init -y
```

> このように、複数の RUN コマンドを「連続で実行する 1 つのコマンド」として扱うことで、イメージレイヤーをまとめて軽量化できます。

2. RUN で apt コマンドを走らせた場合はインストール時に使った apt キャッシュ(ゴミファイル)が残ってしまうため削除する。

3. 使用したい image に slim version があるか DockerHub で探す。
   ※デフォルトの NOde がかなり色々入っている。そのため slim イメージを探す。

---

## dokcer Script関連
## Docker コンテナの動作に必要な設定を起動時に渡す

Dockerコンテナを起動するタイミングで、コンテナの動作に必要な設定を受け渡す方法は2つある。

1. 環境変数を通して渡す
2. コマンドライン引数を渡して渡す。

**どちらの場合も docker run で実行するコマンドの中に設定を含めることになる。**

## docker-entrypoint.sh

dockerで初回起動時のみ特定の処理を行うヘルパースクリプト

>docker run とか docker-compose up -d とかの 初回起動時のみ 処理したいことがある時はどうすればいいんだろう？
>docker restart とか docker-compose restart とか systemctl restart docker の時には動いてほしくないんだ。
>やってみた結果 mariadb + zabbix で初回起動時のみ、構成用の .sql を流し込む。という動作ができるようになりました。

## wait.sh

dbの起動とかを待ってくれる。
>内容はただのシェルスクリプトでポートが LISTEN しているかをチェックしてくれます

---
## ローカル上にLocalStackをDockerで実行

開発用にAWSのサービスをローカル環境に構築できる、LocalStackというプロジェクトがある。素晴らしい。

[参考URL](https://qiita.com/mmclsntr/items/709863ba98a4855988f3)

## Dockerのコンテキストとは

>docker build コマンドを実行したときの、カレントなワーキングディレクトリのことを ビルドコンテキスト（build context）と呼びます。 デフォルトで Dockerfile は、カレントなワーキングディレクトリにあるものとみなされます。 ただしファイルフラグ（-f）を使って別のディレクトリとすることもできます。 Dockerfile が実際にどこにあったとしても、カレントディレクトリ配下にあるファイルやディレクトリの内容がすべて、ビルドコンテキストとして Docker デーモンに送られることになります。

要は**docker buildコマンドを実行した場所**

- 制約
**Dockerはコンテキスト(カレントディレクトリ)の外のファイルにはアクセスできない仕様。**

- ではディレクトリごとにわけた
ルートディレクトリをDockerのコンテキストにすることで、Dockerfileはどんなファイルにもアクセスできるようになりました。
一方で、build時はその分Dockerデーモンという奴にそれだけ多くのファイルを送ることになるので遅くなることがあるようです。

構築時、ビルドコンテキストとして現在のディレクトリ以下にある全てのファイルやディレクトリをDocker deamonに送信してしまいます。ビルドコンテキストに余分なディレクトリ・ファイルがあると、build時に時間がかかる、メモリを消費する原因となります。例えば、ビルドコンテキストに100MBのファイルがあるとimageのサイズが100MBプラスとなってしまいます。このような事態を防ぐためにも**Dokcerfile用のディレクトリを作成し、そのディレクトリには無駄なファイルは配置しないようにすべきです。**

## docker ignore the

.dockerignoreを使ったファイル除外の指定
Dockerfile用のディレクトリを作ったがそのディレクトリ内にビルドコンテキストとして含みたくないファイルが存在する、もしくはDockerfileをアプリのソースファイルが配置されているディレクトリと同じにしたいということもあると思います。

**そんなときに .dockerignore を用いると、ビルドコンテキストとして無視します。**

## docker network

コンテナ内の/etc/hostファイルで定義されているそう。以外に簡単

## マルチステージビルド

[参考URL](https://qiita.com/carimatics/items/01663d32bf9983cfbcfe)

- マルチステージビルド以前
サイズを小さく保ちながらDockerイメージをビルドすることは、最もやりがいのあることの一つ　。
**Dockerfile内の各々の命令ではイメージにレイヤが追加される。**
**したがって、次のレイヤを作成する(次の命令に移る)前に、不要な生成物のクリーンアップする必要があります。**
本当に効率的なDockerfileを作成するには、レイヤをできる限り小さく保ち、各レイヤが前のレイヤの生成物から必要なものを確保するために、シェルのトリックやその他のロジックを採用する必要がありました。
実際に、開発用にはアプリケーションのビルドに必要なすべてが含まれるDockerfileを使用し、プロダクト用にはアプリケーションおよび実行に必要なもののみが含まれるスリム化されたDockerfileを使用することは非常に一般的でした。
これがいわゆる"ビルダーパターン"です。
2つのDockerfilesを保守することは、理想的ではありません。

---

## ここからはさわって学ぶクラウドインフラ本

- コンテナ
コンテナはシステムの実行環境を隔離した空間のこと。
アプリケーションの実行に必要なプログラムやライブラリ、**各種設定ファイルなどをワンパッケージにし隔離して実行するための仕組み。**
コンテナのメリットはそれをコピーして別のコンピューターで動かすのが容易なこと。

システム開発・運用の現場では、「開発者が作ったプログラム一式を検証機にコピーする」「検証機で動作確認して問題なければ本番機にコピーする」「冗長性や負荷分散のために、同じ構成のものコピーして多数台用意する」というように、そのコピーを作りたいことが、よくある。
コンテナ技術を使えば操作が容易になり、コピーや設定漏れを防げます。またシステムのアップデートも、コンテナを差し替えるだけで済むようになります。

## Docker イメージ

2種類
Dockerイメージには基本的なディストリビューションとアプリケーション入りのがある。
**カスタマイズするには基本的なディストリビューション入り(Linuxのみ)を使う**

Dockerイメージに手を加える時は、アプリケーション入りDockerイメージではなく、LinuxのみDockerイメージをベースとするほうがやりやすい。
→ただ、そうしたカスタムは手間がかかり、1つひとつ手作業していると作業漏れが起こる可能性が少なくない。そこでコンテナに手を加えたあと、**そのコンテナをカスタムDockerイメージに変換する。**

![dockerimage](image/dockerimage.png)

- ではカスタムのDockerイメージを作るのは？
カスタムのDockerイメージを作るときは、手作業でファイルコピーやコマンドを実行するのではなく、Dockerfileにファイルコピーや実行したいコマンドなど一連の設定を記述し、そのファイルを適用して作るのが一般的。
**カスタムDockerイメージはDocker HubのようなDockerレジストリに登録できる。**

## Docker desctop

Docker Desctopの内部にはLinuxカーネルが含まれており、WindowsやmacOSでありながらもLinuxを実行することで、その上でDockerを使えるようにしたもの。

## 仮想サーバとコンテナの違い

仮想サーバは1台の物理的なサーバの中に復数の仮想的なサーバを作り、**物理的なサーバを仮想的なサーバが分割して使う**

コンテナはサーバをブナkつする技術ではない。**サーバはあくまでも1台で、その中にたくさんのアプリケーションが隔離して実行されているのにすぎない。**

## コンテナの破棄

docker stopしてもコンテナはずっと残り続けるということ。
**これは明らかにディスクを圧迫する。もう使わない場合は停止ではなく明示的に破棄にするべき**
docker rm で完全削除できる。

## イメージの破棄

Dockerイメージが消費する容量も馬鹿にならない。
**ダウンロードしたイメージはコンテナを破棄しても残ったまま。**
※これはもう一度、同じDockerイメージからコンテナを作ろうとした時に、再ダウンロードしなくても済むようにするため。

`$docker image ls`
`$docker image rm` → `$docker rmi`とかける。


## docker runについて

`$docker run`というコマンドは

`$docker pull`,`$docker create`,`$docker start`という3つの一連のコマンドをまとめて実行している。

## タグ

イメージ名のタグ(tag)はDockerイメージの製作者が名付けた分類名のこと。
**※タグはリソース版や、開発版、バージョン番号などを示すのに使われる。**

タグ名を省略する時は、最新版を意味する**latest**というタグが指定されたものとみなされる。

## 本番運用

本番の安全運用は、Dockerホストをマネージドサービスにしてある程度、任せてしまうのが無難。
AWSにはAmazon ECSというコンテナを運用するマネージドサービスがある。

- マネージドサービス
管理されたManagedサービスという意味で、**運用管理をクラウドに任せることができるサービスのことを言う。**
仮想サーバのEC2は自分で管理するサービスのためアンマネージドサービスという。

- さらなるスケーリングや堅牢性がほしいときはKubernetesを使う。

- どのイメージをダウンロードすればいいのか
納品にあたっては、動作検証するはず、動作検証後にコンテナのバージョンが変わるということはシステムが変わること。
本番環境でDockerを利用するのであれば、タグ名を省略せずに明示的に指定して、特定のイメージの版に利用する(それよりも新しい版ができたとしても使わないようにする。)
**もちろん、その特定イメージの版のまま使い続けるという意味ではありません。**ある程度の期間が経ったら、そのときの最新版で再度動作検証し、問題なければ、その版に差し替えるというように、コンテナの定期的なアップデートは必須です（そうしなければ、脆弱性などに対応できない。

## オプション

### -pオプション(略称 publish)

ポート番号をマッピングするもの
`-p ホストのポート番号:コンテナのポート番号`
udpを選択する場合には、ポート番号を`ポート番号/udp`とする。
**※Dockerでは、pオプションを指定しない限り、DockerホストとDockerコンテナとの通信は繋がらない。**
**※マッピングの状態は`docker port `コマンドで確認ができる。**

### -vオプション

コンテナの特定のディレクトリにホストのディレクトリをマウントする設定。
**-mountオプションを同様**

`-v ホストのディレクトリ:コンテナのディレクトリ`

## -ditオプション

-ditは` -d, -i, -t`の3つのオプションの組み合わせ。

-dが端末から切り離してバックグラウンドで実行
-iと-tはコンテナを端末(キーボードとディスプレイ)から操作するためのオプション

アタッチの場合(-dを指定しない時)は端末と接続された状態のため、端末からの操作は、そのままコンテナ内で実行中の既定のコマンドに流されます。だからこそ、［Ctrl］＋［C］を押すことで、そのコマンドが終了する。
デタッチのときは、端末とは切り離されているので、コンテナ内で実行されているコマンドに対して、何かキー操作することはできません。デタッチの状態とアタッチの状態は、実行中に切り替えることができる。

![dit](image/ditオプション.png)

## -iオプション

標準入出力およびエラー出力をコンテナに対して結びつけます。その結果、キー入力した文字はコンテナに渡され、コンテナからの出力が画面に表示されるようになります。iオプションを指定しないと、キー入力はコンテナに伝わりませんからこうしたキーが効きません。そしてコンテナからの出力が届きませんから、httpdコンテナの例で言えば、いま見てきたように、画面に各種ログが表示されることもありません。

## -tオプション

-tオプションは、pseudottyと呼ばれる疑似端末を有効にする設定です。疑似端末は、カーソルキーやエスケープキー、［Ctrl］キーなどで操作するためのものです。このオプションを指定せず、iオプションのみだと、これらのキーが使えません。つまり、［Ctrl］＋［P］、［Ctrl］＋［Q］キーが効きません。

デタッチで起動後、操作の必要がないのであれば-iや-tのオプションは必要ない。
しかし、後でアタッチするなどして端末から操作したいときは-iや-tを指定する必要がある。

---

## docker コンテナ内のファイルと永続化

Dockerコンテナは、それぞれが隔離された実行環境。**コンテナを破棄すればその中にあるファイルは自ずと失われる。**
`$docker rm`このコマンドをして再度`docker run`をするとコンテナIDが変わるとおもう。前のコンテナとは別のものとなっている証拠。

## ホストからファイルをコピーする

コンテナの中のファイルを変更するにはどのようにすればいいか

docker execで、/bin/bashを起動しそこでnanoエディタなどを起動して、編集する方法。
しかしapacheなどではファイルサイズを小さくするためnanoエディタなどが入っていないおそれ

そこで便利なのが`docker cp`コマンド
※docker cpはパーミッションをそのままコピーする。ディレクトリも再帰的にコピーする。
※docker cpは/prop, /sys, /dev, tmpfs配下のようなシステムファイルはコピーできない。**こうしたファイルをコピーしたい時には標準入出力経由でコピーする。**

## 上記を含めると、コンテナは一度起動したら破棄してはいけないのか？

違う。そうではなく**コンテナは失ってはいけないデータは外に出すように設計する。**

- ではどうすればいいか？

**マウントする。**
コンテナは実行するシステムと扱うデータは別に管理することが推奨されている。
またコンテナの設計として**実行するシステムと扱うデータは別に管理することが推奨されている。**

`docker run -v`でマウントをする。
つまりデータをコンテナの外に出す。
**Dockerホストのディレクトリをマウントしているのは(外に出しているのと同意)そのためコンテナを削除しても消えないのは当たり前**

![mount](image/mount.png)

## コンテナ間のデータ共有にも利用できる。

マウントする手法はデータを失わないようにするだけではなく、別の方法もある。
**それはコンテナ間でのデータ共有。1つの場所を2以上のコンテナで同時にマウントすることもできる。**

そのため./docker/nginx/nginx.confなど、設定ファイルをプロジェクトに用意しているのは、コンテナ内のnginxの設定ディレクトリにマウントし本来のnginx.confを上書きしている。
この方法であれば、Dockerホストに設定ファイルが残るため設定のバックアップが容易。

※マウントはディレクトリに対して設定するのがほとんどだが、設定ファイルだけをマウントすることも可能。

Dockerホストにあらかじめディレクトリを作っておき、それをマウントする方法を**バインドマウントという**

- マウント種類

バインドマウント
Dockerホストにあらかじめディレクトリを作っておき、それをマウントする方法を**バインドマウントという**

ボリュームマウント
ボリュームマウントは、ホスト上のディレクトリではなく、**DockerEngine上で確保した領域をマウントする方法。**
確保した場所のことを、データボリュームもしくは略して「ボリューム」と言う。

![bindmount](image/bindmount.png)
